{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0c8087",
   "metadata": {},
   "source": [
    "# NX-414 - Mini-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f1b3a",
   "metadata": {},
   "source": [
    "Group members: Kolly Florian, Mikami Sarah, Montlahuc Louise\n",
    "\n",
    "## Project description\n",
    "The objectives of the project are:\n",
    "- Predict neural activity using linear regression from images and from neural network layers.\n",
    "- Quantify the goodness of the model\n",
    "- Compare the results across the network layers and between trained/random neural network\n",
    "- Predict the neural activity using a neural network in a data-driven approach\n",
    "- Develop the most accurate model for predicting IT neural activity\n",
    "\n",
    "Specifically, we use the data from the following [paper](https://www.jneurosci.org/content/jneuro/35/39/13402.full.pdf). The behavioral experiment consisted in showing to non-human primates some images while recording the neural activity with multielectrode arrays from the inferior temporal (IT) cortex. In the data we provided you, the neural activity and the images are already pre-processed and you will have available the images and the corresponding average firing rate (between 70 and 170 ms) per each neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ee37e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL NECESSARY IMPORTS\n",
    "from abc import ABC\n",
    "import inspect\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "import gdown\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR, SequentialLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from fvcore.common.registry import Registry\n",
    "from torchvision.models import resnext101_32x8d, ResNeXt101_32X8D_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6db4f1",
   "metadata": {},
   "source": [
    "## Models interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feeadfc",
   "metadata": {},
   "source": [
    "For genericity and reusability, we define an interface for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e13781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IModel INTERFACE\n",
    "class IModel(ABC, nn.Module):\n",
    "    \"\"\"\n",
    "    Abstract base class for a model.\n",
    "    This class defines the interface that all model classes must implement.\n",
    "    All models inheriting from this class should have a self.model attribute!\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.PCs = dict()\n",
    "        self.PCA = None\n",
    "        self.ACTs = dict()\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.model(images)\n",
    "    \n",
    "    def get_layers(self):\n",
    "        \"\"\"\n",
    "        Returns the layers on which to do the linear probing.\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        layers_name = [name for name, _ in self.model.named_children()]\n",
    "        for name in layers_name[-4:]:\n",
    "            module = self.model.get_submodule(name)\n",
    "            layers.append((name, module))\n",
    "        return layers\n",
    "        \n",
    "    def get_activations(self, hook_name):\n",
    "        \"\"\"\n",
    "        Returns the activations of the model.\n",
    "        The hook_name can be 'all' for all activations or 'pca' for 1000 principal components.\n",
    "        \"\"\"\n",
    "        if hook_name == 'all':\n",
    "            return self.ACTs\n",
    "        elif hook_name == 'pca':\n",
    "            return self.PCs\n",
    "        else:\n",
    "            raise ValueError(\"Invalid hook name. Use 'all' or 'pca'.\")\n",
    "        \n",
    "    def reset_activations(self):\n",
    "        \"\"\"\n",
    "        Resets the activations of the model.\n",
    "        \"\"\"\n",
    "        self.PCs = dict()\n",
    "        self.ACTs = dict()\n",
    "\n",
    "    def _get_PCs_hook(self, module, input, output, layer_name):\n",
    "        print('Layer:', layer_name)\n",
    "        activations = output.detach().cpu().numpy().reshape(output.shape[0], -1)\n",
    "        print('Activations shape:', activations.shape)\n",
    "        pca = PCA(n_components=1000)\n",
    "        print(pca.type())\n",
    "        self.PCA = pca\n",
    "        pca_features = pca.fit_transform(activations)\n",
    "        print('Principal components shape:', pca_features.shape)\n",
    "        self.PCs[layer_name] = pca_features\n",
    "\n",
    "    def _get_activations_hook(self, module, input, output, layer_name):\n",
    "        activations = output.detach().cpu().numpy().reshape(output.shape[0], -1)\n",
    "        self.ACTs[layer_name] = activations\n",
    "    \n",
    "    def register_hook(self, hook_name):\n",
    "        \"\"\"\n",
    "        Registers a hook to the model.\n",
    "        The hook can be 'all' for all activations or 'pca' for 1000 principal components.\n",
    "        \"\"\"\n",
    "        handles = []\n",
    "        for name, layer in self.get_layers():\n",
    "            if hook_name == 'all':\n",
    "                handle = layer.register_forward_hook(lambda m, i, o, n=name: self._get_activations_hook(m, i, o, n))\n",
    "            elif hook_name == 'pca':\n",
    "                handle = layer.register_forward_hook(lambda m, i, o, n=name: self._get_PCs_hook(m, i, o, n))\n",
    "            handles.append(handle)\n",
    "        return handles\n",
    "    \n",
    "    def change_head(self, layer, num_classes):\n",
    "        \"\"\"\n",
    "        Sets a final head (classification or regression) after the indicated layer.\n",
    "        \"\"\"\n",
    "        return ModifiedModel(self.model, layer, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e654f1f",
   "metadata": {},
   "source": [
    "For finetuning models, we create a class that extends our generic model interface ```IModel``` and contains both the original model alongside the modified model. As we are testing multiple models and multiple finetuning methods, our goal is to stay as generic as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0711176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModifiedModel class\n",
    "class ModifiedModel(IModel):\n",
    "    def __init__(self, base_model, insert_after, num_classes):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.insert_after = insert_after\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Extract layers up to the insertion point\n",
    "        self.features = nn.Sequential()\n",
    "        for name, module in base_model.named_children():\n",
    "            self.features.add_module(name, module)\n",
    "            if name == insert_after:\n",
    "                self.layer = (name, module)\n",
    "                break\n",
    "\n",
    "        # TODO testing freezing the layers\n",
    "        # for param in self.features.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        # Determine input dim for new head\n",
    "        dummy_input = torch.randn(1, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            out = self._forward_features(dummy_input)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        head_in_features = out.shape[1]\n",
    "\n",
    "        # Define new head (classification or regression)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(head_in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        for name, module in self.features.named_children():\n",
    "            if isinstance(module, nn.ModuleList):\n",
    "                for submodule in module:\n",
    "                    x = submodule(x)\n",
    "            else:\n",
    "                x = module(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def get_layers(self):\n",
    "        return self.layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485a44a",
   "metadata": {},
   "source": [
    "We then create a build function that takes a model name and a set of parameters, and returns the corresponding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dcfe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_REGISTRY = Registry(\"MODEL\")\n",
    "MODEL_REGISTRY.__doc__ = \"\"\"\n",
    "Registry for models.\n",
    "\n",
    "The registered object will be called with `obj()`.\n",
    "The call should return a `nn.Module` object.\n",
    "\"\"\"\n",
    "\n",
    "def accepts_seed(cls):\n",
    "    init = cls.__init__\n",
    "    sig = inspect.signature(init)\n",
    "    return 'seed' in sig.parameters\n",
    "\n",
    "def make_model(name, seed):\n",
    "    \"\"\"\n",
    "    Builds the video model.\n",
    "    Args:\n",
    "        name (string): name of the model to build.\n",
    "    Returns:\n",
    "        model (nn.Module): the built model.\n",
    "    \"\"\"\n",
    "    model = MODEL_REGISTRY.get(name)\n",
    "    if accepts_seed(model):\n",
    "        model = model(seed)\n",
    "    else:\n",
    "        model = model()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848aebf",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe7ba9",
   "metadata": {},
   "source": [
    "Let's now setup the loading of the data. We start with some utility functions that were given in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utils\n",
    "def download_data(path_to_data):\n",
    "    if not os.path.exists(path_to_data):\n",
    "        os.makedirs(os.path.dirname(path_to_data))\n",
    "    output = \"IT_data.h5\"\n",
    "    data_path = os.path.join(path_to_data, output)\n",
    "    if not os.path.exists(data_path):\n",
    "        url = \"https://drive.google.com/file/d/1s6caFNRpyR9m7ZM6XEv_e8mcXT3_PnHS/view?usp=share_link\"\n",
    "        gdown.download(url, os.path.join(path_to_data, output), quiet=False, fuzzy=True)\n",
    "\n",
    "def load_it_data(path_to_data):\n",
    "    \"\"\" Load IT data\n",
    "\n",
    "    Args:\n",
    "        path_to_data (str): Path to the data\n",
    "\n",
    "    Returns:\n",
    "        np.array (x6): Stimulus train/val/test; objects list train/val/test; spikes train/val\n",
    "    \"\"\"\n",
    "\n",
    "    datafile = h5py.File(os.path.join(path_to_data,'IT_data.h5'), 'r')\n",
    "\n",
    "    stimulus_train = datafile['stimulus_train'][()]\n",
    "    spikes_train = datafile['spikes_train'][()]\n",
    "    objects_train = datafile['object_train'][()]\n",
    "    \n",
    "    stimulus_val = datafile['stimulus_val'][()]\n",
    "    spikes_val = datafile['spikes_val'][()]\n",
    "    objects_val = datafile['object_val'][()]\n",
    "    \n",
    "    stimulus_test = datafile['stimulus_test'][()]\n",
    "    objects_test = datafile['object_test'][()]\n",
    "\n",
    "    ### Decode back object type to latin\n",
    "    objects_train = [obj_tmp.decode(\"latin-1\") for obj_tmp in objects_train]\n",
    "    objects_val = [obj_tmp.decode(\"latin-1\") for obj_tmp in objects_val]\n",
    "    objects_test = [obj_tmp.decode(\"latin-1\") for obj_tmp in objects_test]\n",
    "\n",
    "    return stimulus_train, stimulus_val, stimulus_test, objects_train, objects_val, objects_test, spikes_train, spikes_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce109f0",
   "metadata": {},
   "source": [
    "Let's now create a function for retrieving the data we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea70b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Get the data from the IT dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: tuples (stimulus, objects, spikes) for training and validation sets.\n",
    "    \"\"\"\n",
    "    stimulus_train, stimulus_val, stimulus_test, objects_train, objects_val, objects_test, spikes_train, spikes_val = load_it_data('./data/')\n",
    "    return (stimulus_train, objects_train, spikes_train), (stimulus_val, objects_val, spikes_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594daa0",
   "metadata": {},
   "source": [
    "## Testing basic models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aad0ff",
   "metadata": {},
   "source": [
    "We start by analyzing the results of using simple models. We here test linear and ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb6a7c",
   "metadata": {},
   "source": [
    "## Loading the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c2a31",
   "metadata": {},
   "source": [
    "Our best $R^2$ score was obtained by finetuning in a data-driven way a pretrained ResNeXt model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ae660",
   "metadata": {},
   "outputs": [],
   "source": [
    "@MODEL_REGISTRY.register()\n",
    "class ResNeXt(IModel):\n",
    "    def __init__(self):\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.model = resnext101_32x8d(weights=ResNeXt101_32X8D_Weights.IMAGENET1K_V1)\n",
    "\n",
    "base_model = make_model('ResNeXt', 0)\n",
    "model = base_model.change_head('layer4', 168)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe6df0",
   "metadata": {},
   "source": [
    "We can now load our saved weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load('best_model.pt')\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d377c",
   "metadata": {},
   "source": [
    "## Inference time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54540d1b",
   "metadata": {},
   "source": [
    "Let's try our model on the validation data and check the $R^2$ score we obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = get_data()\n",
    "out = model(val_data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nx414",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
